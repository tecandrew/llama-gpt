version: '3.9'

services:
  ui:
    image: lafcadio27/llama-gpt-ui:latest
    build:
      context: ./ui
      dockerfile: no-wait.Dockerfile
    container_name: llamagpt-ui
    restart: unless-stopped
    volumes:
      - ./models:/models
    ports:
      - 3000:3000
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      OPENAI_API_KEY: 'sk-XXXXXXXXXXXXXXXXXXXX'
      OPENAI_API_HOST: '${OPENAPI_HOST:-http://host.docker.internal:8000}'
      NEXT_PUBLIC_DEFAULT_SYSTEM_PROMPT: "${DEFAULT_SYSTEM_PROMPT:-You are a helpful and friendly AI assistant. Respond very concisely.}"
      DEFAULT_MODEL: /models/${MODEL_NAME:-codellama-7b-instruct.Q4_K_M.gguf}

